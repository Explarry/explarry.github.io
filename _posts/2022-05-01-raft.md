---
layout: post
title:  raft
categories: raft
---

# raft 的定义
管理日志副本的共识算法

# raft 的目的
* （与 paxos 相比）便于工程实现
* （与 paxos 相比）便于教学，即易于理解

> 为了达到上述两个目的

* raft 被划分成多个部分
  * leader election
  * log replication
  * security
  * membership changes

* raft 优化了状态空间
  * 减少了状态数目
  * 减少了达到不一致的路径数目

# raft 的特征

* strong leader
  * log 只会从 master 流向 follower

* fast election
  * 通过随机的定时器（具体的，是随机的 election timeout），简单快速地解决达成共识前的冲突（具体地，是 vote split）

* membership changes
  * joint consensus approach？

# 复制状态机
replicated state machine

## 架构

> client

* client 的请求会被转发到 leader 上

> leader

* leader 全权负责 replicated log 的管理
  * 接受从 client 发来的 log entries
  * 复制 log entries 到其它的服务器
  * 判断何时能够安全地把 log 应用到状态机上
* leader 的 log 是 append-only 的，绝不会删除，也不会重写

> follower

> client --> consensus module --> replicated log --> state machine --> client

* consensus module 的作用就是保证不同服务器上的 replicated log 完全一致（log 上记录的命令一致、命令的顺序一致）

> 为了达到上述目的，共识算法要求

* 在 non-byzantine 情况下，无论遇到什么失败（网络延时、网络分区、重复、重排序、丢包），也绝不返回错误的结果
* 如果超过半数的 server 是正常的，那么就能够正常对外提供服务。此外，异常的 server 也可以基于持久化数据来恢复，重新加入集群
* 不对时间有强依赖，这样可以避免时钟错误、消息延迟等极端情况带来的影响
* 如果超过半数的 server 已经达成共识，那么这次共识的结果就可以对外了，其余的较慢的 server 不会拖累整体性能

# paxos 的问题

# 理解驱动设计
design for understandability

> 易于理解的一个重要好处是，便于在工程中对算法实现进行拓展

> 达到易于理解这个目的的两个方式

* 分解
  * leader election
  * log replication
  * security
  * membership changes
* 简化
  * 减少状态数目，让系统更加紧凑（coherent）
    * 日志不允许有 hole？
    * 减少日志可能达到不一致的路径数目
  * 简化选举过程
    * 引入随机性（chose any, it dosen't matter）

# raft 算法细节

## leader

> leader 全权负责 replicated log 的管理

* 接受从 client 发来的 log entries
* 复制 log entries 到其它的服务器（并行的 rpc 调用）
* 判断何时能够安全地把 log 应用到状态机上

> 在 leader 的基础上，需要解决三个字问题

* leader election
  * 一个 leader 失败时，选举新的 leader
* log replication
  * leader 将自己收到的日志扩散到集群中
  * leader 强制要求其它 server 的 log 与自己的保持一致
* safety
  * 如果任何一个 server 已经将一条 log entry 应用到它自己的 state machine，那么其它的 server 也必须将同样 log index 的、同样 log entry 应用到它们各自的 state machine

## term

> term，可以理解为任期

> 任期的定位是逻辑时钟

* 任期的长度是任意的
* 任期的以一次成功的选举开启
* 任期用连续的 integer 标志
* 任期内至多有一个 leader
  * 如果出现 split vote 的局面，这个 term 就没有 leader，很快之后重新开始一轮选举

> side effect

* 不同的 server 可能在不同的时间观察到任期间的过渡期

## server state

> 状态转移图

* follower
  * in
    * server 启动 --> follower
    * candidate 发现 current leader 或者 new term --> follower
    * leader 发现 higher term --> follower
* candidate
  * in
    * follower timeout，开始选举 --> candidate
    * candidate timeout，重新开始选举 --> candidate
* leader
  * in
    * candidate 收到过半的 votes --> candidate

## rpc

> raft 算法中最少只需要两种 rpc

* requestVote，cadidate 发起投票
* appendEntries，leader 发起 log entry replicateon，也用作心跳

> 其它 rpc

* transferSnapshot

## leader election

> 第一轮

* 各个 follower 随机地在固定的范围内（150-300ms）选取 election timeout
* 在这个期间内没有收到有效的心跳，就超时，然后自增 term 并且发起新的选举，进入 candidate 状态
  * 有效即要求：心跳中的 term 大于等于当前 server 的 term
  * candidate 发起选举投票总是投自己

> 第 n 轮

* 如果发生 vote split，那么各自重新发起选举，随机地选在固定范围内（150-300ms）选取 election timeout

> 投票的策略

* 收到投票请求的 server，会比较投票请求中 term 与自身当前 term 的大小。对于有效的投票请求，采取谁先来投谁的策略
* 如果一个 candidate 收到过半的选票，那么它立即会向其它 server 发出 heartbeat，尝试建立自己的权威，即阻止发起新的选举
  * 只有心跳中携带的 term 是集群中最大的，权威才能够建立起来

> candidate 在 election 的过程中如果收到其它服务器发来的心跳，即 appendEntries，那么就会比较自己当前 term 与心跳中携带的 term 的大小，判断其权威新，如果对方的 term 大于等于自己的 term，那么自己就放弃 election，转变成 follower

## log replication

> log 中的每一条 entry 有三个字段组成

* log index
* term
* state machine command

> log replication 流程

* client 发起请求
* leader 收到请求，append 到自己的 log，然后向所有其它 server 并行地发起 appendEntries 调用
* 当 entry 被安全地复制后（超过半数的 follower 已经回复成功），leader 将这条 entry 应用到自己的状态机，然后向 client 回复
* 即使 leader 已经回复 client，但是如果有任何 follower 没有及时的回复（follower crash、follower 跑的慢、网络问题等），leader 会不断地向这些 follower 发起重试，直到成功

> log matching property

* 如果两个不同 server 上的 log entry 拥有一样的 log index 和一样的 term，那么这两个 log entry 的 command 一定是相同的
* 如果两个不同 server 上的 log entry 拥有一样的 log index 和一样的 term，那么这两个 log 中两个 log entry 之前的 entries 一定是相同的
 
> log inconsistency

相比于 leader， follower 可能

* 缺失 entries
* 多出 entries
* 包含不一致的 entries

> raft 处理不一致的方式是强制不一致的 follower 复制 leader 的 log，这也就意味着 follower 中的 log 会被重写

> 如何确定不一致的开始位置？follower 会根据 appendEntries 中的 prevLogIndex 和 prevLogTerm 做一致性检查，不一致则拒绝。然后

* 方式一：单纯的依赖 leader 在收到拒绝后，把 index 减一，并充重试
  * 这种方式有多少冲突的 entries 就需要重试 appendEntries 多少次
* 方式二：follower 回复的时候也携带上一些信息（follower 的 log 上发生冲突所在的 term，以及该 term 期间的第一个 log index），供 leader 来判断 index 减小多少
* 其它方式：二分搜索
  * 这种方式有多少冲突的 terms 就需要重试 appendEntries 多少次
* 方式一通常是足够的，failure 是偶发的，不一致通常不会太多

## 安全性

> follower 的 log 可能会被重写，而 follower 先前也可能是 leader，而 leader 有 commit log entry 的权限，即修改状态机的权限，那么如何保证状态机一致？

* leader completeness property 是确保 state machine 一致的另一个重要约束

> 如何达到 leader completeness

* voting 的过程中，一个 candidate 除了得到超过半数的 votes，还必须拥有全部的 committed log entries，它才能够成为 leader

* requestVote 中携带 candidate 的 commit 信息，voter 会比较自己和对方的 commit 信息，只有满足 candidate 的 commit 信息比自己的更 up-to-date，voter 才会给这个 candidate 投票

* 这样只要 candidate 获得了超过半数的选票，就说明具备 commit completeness
  * 最一开始没有 log entry，满足 commit completeness
  * 后续 raft 始终确保超过半数这一点，那么给 candidate 投票的超过半数的 server 其中之一必然具备 commit completeness。这个具备 commit completeness 的 server 既然给 candidate 投票了，表示它确认了这个 candidate 也是 commit completeness 的

> 如何判断谁的 log 更加的 up-to-date

* 比较 term，term 越大，越 up-to-date
* term 相同，比较 log 长度（log 即末尾的 entry index），长度越长，越 up-to-date
