---
layout: post
title:  operation system
categories: operation_system
---
# 1 操作系统的历史

* 多任务处理是操作系统诞生的驱动因素，或者说操作系统解决的问题是如何高效地进行多任务处理

  如果单任务独占，那么不需要操作系统

  发展的进程：

  单任务独占 --> 批处理 --> 多任务处理

* 硬件上

  * 处理器的进步使得计算效率大大提升
  * 内存的增大使得计算机同时装载多个程序成为可能

* 对 cpu 进行分时复用的关键技术是中断

* 虚拟化的目的是提供优秀的 api，让程序的功能得以实现，并且在使用时好像是在独占设备资源

* three easy pieces

  * 虚拟化

    进程，虚拟内存，设备抽象

  * 并发

    cpu 的分时复用，进程/线程间的通信

  * 持久化

    文件系统



# 2 应用眼中的操作系统

* coreutils

  体积更小的替代品，busybox

* ubuntu packages 支持文件名检索

  当系统缺少某些东西时，这是一个非常好的检索入口

* elf

  executable linkable format，可执行的可链接的格式

  * xxd，反汇编命令，可以用来分析 elf 格式的文件
  * readelf，可以用来查看 elf 格式的文件的信息



# 3 多处理器并发编程

* 编译器优化的后的汇编指令会丢失原代码的顺序

  * 保证顺序：volatile，barrier

* 中断机制使得 cpu 在不同程序的汇编指令之间跳转，造成代原码的原子性丢失

  * 保证原子性：multual exclusive

* cpu 在执行指令时，为了增加 cache 的命中率，对于没有依赖的指令会进行重排，例如让一个指令等待一段时间后再去执行，从而丢失了可见性

  * 可见性指的是多个处理器访问共享内存的不能做到一致性，例如一个处理器上执行了写内存指令，对于另一个处理器不可见。

  * 保证可见性：fence 指令，原子性指令



# 4 理解并发程序的执行

* 程序 <==> 有限状态机 <==> 有向图

  有限状态即状态的数目是有限的

  一个状态就是一个时刻内存和寄存器的值

  计算机提供的执行即状态转移的条件

* 计算机提供的指令

  * 确定性的指令，deterministic

  * 非确定性的指令，non-deterministic，例如，

    tdtsc/tdtscp，读取 cpu 的时钟计数

    rdrand，读取传感器上的白噪声，真随机

* syscall 也能够带来不确定性

  这是大部分程序的不确定性的来源

* 程序不确定性的来源

  程序接收操作系统的输入，操作系统接收硬件的输入，硬件接受真实物理世界的输入

* 有限状态机，把它当作一个分析处理问题的工具，它有很多的应用

  * 超标量处理器，superscale

    在一个时钟周期内处理一个等价于多个指令的复合指令，相当于在状态之间跳跃

  * 静态分析，例如静态代码检查，代码调试

    gdb 的回退功能

  * 动态分析，检查运行时状态机的执行

* 举例，利用有限状态机可以证明 perterson 算法的正确性

  * 互斥算法的要求两点：

    safety，坏的情况永远不会发生，即不能出现两个同时进入临界区；

    liveness，好的情况永远会发生，即总有一个能够进入临界区

  * perterson 算法

    类比：两个线程是两个人，临界区是厕所，x、y 是两人各自是否需要上厕所的旗子，t 是厕所挂到厕所上的牌子。

    ```c
    // 初始
    x = fasle;
    y = false;
    t = t1;
    
    // thread1
    x = true;                  // pc1=1
    t = t1;                    // pc1=2
    while y && t == t2;        // pc1=3
    do_something();  // 临界区  // pc1=4
    x = false;                 // pc1=5
    
    // thread2
    y = true;                  // pc2=1
    t = t2;                    // pc2=2
    while x && t == t1;        // pc2=3
    do_something();  // 临界区  // pc2=4
    y = false;                 // pc2=5
    
    // 共享的内存 x, y, t
    // 各自的程序计数 pc1, pc2
    // 状态 (pc1, pc2, x, y, t)
    // 坏的情况 (4, 4, _, _, _)，safety 即在有向图中这个状态是不可达的
    // 好的情况 (4, !4, _, _, _), (!4, 4, _, _, _)，liveness 即有向图中这两个状态都是可达的，并且不存在可达的环
    // 画有向图可证
    ```

  * perterson 算法在现代处理器上因为可见性的原因是错误的

    任意一个线程在 load(x), store(x), load(t) 时，因为三者时不同的变量，所以处理器可以进行指令重排

# 5 并发控制

* 从锁的角度来看指令

  * load 指令，读共享内存（睁眼看，不能动手）
  * store 指令，写共享内存（动手写，闭着眼睛）
  * 其它本地计算指令

  只有 load 和 store 指令的影响需要考虑

  假设状态机每次至多执行一次 load 或者一次 store 指令，即指令是原子的

  例如：在 x86 的架构下如果一条汇编执行需要超过一次 load/store，那么在执行时会被拆成更小的指令来执行

  另外：现代多 cpu 架构设计为了使得单线程具有更快的运行速度，使用了多级缓存。

  * 一个 cpu 执行了一个 store 指令，会先写入 cpu 的 store buffer。buffer 满才会写入下一级的缓存，最终到共享内存
  * 一个 cpu 执行了一个 load 指令，同样地它也是先到 store buffer 里面找，其次才去下一级缓存找，最终从共享内存读取。

  为什么这样的设计可行，因为单线程的本地指令执行数量级要远远大于共享内存的相关指令执行数量级，所以更重要的是使得单线程具有更快的运行速度。

* 软件不够，硬件来凑

  由于以上种种原因，纯软件的实现锁复杂性太高，非常容易出 bug。

  相反地，硬件只要能保证哪怕一点点的互斥性，软件上的实现也会变得非常轻松。

* 实现原子性的硬件指令

  test and set, tas

  exchange, xcg

  add one

  load reserve + store sweep, lr+ss

  可以实现一段代码的原子性

* 无论利用怎样的硬件指令实现锁，实现代码中都需要不断地循环



# 6 硬件眼中的操作系统



# 7 并发控制

## 自旋锁存在的问题

### bug 1 锁的公平性

* 无论是单处理器上还是多处理器上，自旋锁可以实现互斥性，但是存在公平性问题：

  两个线程 a，b 分别运行在同一个 cpu 上，其中 a 获得锁、执行任务、释放，a 仍然会大概率获得锁。原因是执行任务的时间区间远大于释放锁后争抢的一瞬间，cpu 在跑完线程 a 释放锁的指令后的一瞬间发生中断概率远远小于在释放锁后，所以 a 大概率会继续获得锁。

  此外，如果是切换出去到其它获取同一个锁的线程，那么这个线程只能够 spin，浪费了 cpu 时间。如果是切换出去到其它处理另外的任务的线程，那么就无所谓。

* 关中断 + spin lock

  默认的前置条件：中断的算法知道一个 cpu 长期没有发生中断，开中断后会马上发起一次中断

  上锁：先关中断，再上锁

  解锁：先解锁，再开中断

  这里的顺序是一个优化点。如果反过来先开上锁，再关中断，那么存在一种可能性——上锁后关中断前，发生中断，cpu 切换到另一个获取锁的线程，这个线程在 spin，会浪费 cpu 时间。

* 开关中断这个操作本身是原子的

  asm volatile 保障开关中断的操作不会和它前后的操作因为编译优化而发生顺序调换

  硬件保证了，中断必定发生在指令边界（类似边缘触发）

  中断前输入全部写入内存/缓存

### bug 2 中断标识位

开关中断的操作可以理解成把 eflags push 到堆栈，或者从堆栈弹出

问题一

* 如果一个线程上锁后，在临界区内又尝试去使用另外一把锁，

  那么在内部的锁释放时就会开中断，这违背了我们的要求

* 使用堆栈的思想，记录第一次关中断时的中断标识位，和关中断的次数（堆栈的高度）

问题二

* 如果在中断处理函数中，某个函数使用锁，那么锁释放后会打开中断。但是中断处理函数要求中断时关闭的。
* 应该在最后一次释放锁，打开中断时，回复初始的中断状态，而不是单纯的打开中断

问题三

* 记录中断结构体应该做成 lock local、thread local、还是 cpu local？

  我认为都可以。lock local 的话，记录每次关中断前的中断标识位就可以，开中断就恢复这个标识位；thread local 或者 cpu local 就使用堆栈的方式好了

  cpu local 是更好的选择，因为线程的数目可能会远高于 cpu 的数目

### bug 3 不可重入

如果一个线程获取锁后，在临界区内又尝试获取同一把锁，这时候它会以为锁已经被别的线程获取了，导致一直 spin



### bug 4 不适用于长临界区

其它尝试获取锁的线程或者处理器会进入 spin。严重的情况下，一核持有，七核围观

硬件的中断不能够及时响应



## xv 6 的解决方式

* 简单：

  尝试获取锁时，如果发现锁已经被占用，那么让出 cpu（软件中断）

  如果等待锁的线程非常多，那么很有肯能把大部分线程空转一轮，才轮换到一个可执行的线程

* 进阶：

  尝试获取锁失败后，把当前线程标记成 blocked，并且压入队列、让出 cpu

  释放锁前，从队列取出一个线程，把它标记成 rannable

  中断处理程序每次收到一个中断时，从 rannable 的线程中选择一个运行